# htmlparser-and-screen-scrapper
__python__
__Main reference: Prof. Mike McMillan__

#Html Parser
[view plaintext.py & getlinks.py]
Parsing or syntactic analysis is the process of analysing a string of symbols, either in natural language or in computer languages, conforming to the rules of a formal grammar. The term parsing comes from Latin pars (orationis), meaning part (of speech).

The term has slightly different meanings in different branches of linguistics and computer science. Traditional sentence parsing is often performed as a method of understanding the exact meaning of a sentence, sometimes with the aid of devices such as sentence diagrams. It usually emphasizes the importance of grammatical divisions such as subject and predicate.

#Screen Scraper
[view getquote.py]
Data scraping is a technique in which a computer program extracts data from human-readable output coming from another program.
Web pages are built using text-based mark-up languages (HTML and XHTML), and frequently contain a wealth of useful data in text form. However, most web pages are designed for human end-users and not for ease of automated use. Because of this, tool kits that scrape web content were created. A web scraper is an API to extract data from a web site.

#Web crawler
[view crawl.py]
A Web crawler is an Internet bot which systematically browses the World Wide Web, typically for the purpose of Web indexing.
A Web crawler may also be called a Web spider, an ant, an automatic indexer or (in the FOAF software context) a Web scutter.

Web search engines and some other sites use Web crawling or spidering software to update their web content or indexes of others sites' web content. Web crawlers can copy all the pages they visit for later processing by a search engine which indexes the downloaded pages so the users can search much more efficiently.

Crawlers can validate hyperlinks and HTML code. They can also be used for web scraping (see also data-driven programming).

[Mossein King]
